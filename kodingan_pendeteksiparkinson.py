# -*- coding: utf-8 -*-
"""Kodingan_PendeteksiParkinson

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14YkrTA7hQ8_iJRVpcMegEjUSpdzelUmO
"""

# === IMPORTS UMUM ===
import os, cv2, zipfile, shutil
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# === MODEL KLASIK ===
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from tensorflow.keras.applications import ResNet50
import tensorflow as tf

# === Upload file ZIP di Colab ===
from google.colab import files
uploaded = files.upload()

# === Ekstrak ZIP ===
zip_path = "2Spiral_Parkinson.zip"
extract_path = "Spiral_Parkinson_4Class"

if os.path.exists(extract_path):
    shutil.rmtree(extract_path)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Dataset berhasil diekstrak.")

# === Setup ===
!pip install xgboost --quiet

import os, cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
import tensorflow as tf
from tensorflow.keras.applications import ResNet50

# === Preprocessing & Load Dataset ===
def preprocess_image_grayscale(img):
    img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    img_rgb = cv2.resize(img_rgb, (128, 128))
    return img_rgb

def load_dataset(folder_path, num_classes=4):
    images, labels = [], []
    for label in range(num_classes):
        folder = os.path.join(folder_path, str(label))
        for fname in os.listdir(folder):
            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):
                path = os.path.join(folder, fname)
                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
                if img is not None:
                    img = preprocess_image_grayscale(img)
                    images.append(img)
                    labels.append(label)
    return np.array(images), np.array(labels)

# === Upload ZIP file di Colab ===
from google.colab import files, drive
uploaded = files.upload()

import zipfile
zip_path = list(uploaded.keys())[0]
extract_path = "Spiral_Parkinson_4Class"
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

X_img, y = load_dataset(extract_path)
print("âœ… Dataset dimuat:", X_img.shape)

# === Ekstraksi fitur CNN ===
base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(128, 128, 3))
cnn_features = []
for img in X_img:
    x = np.expand_dims(img, axis=0)
    x = tf.keras.applications.resnet50.preprocess_input(x)
    feat = base_model.predict(x, verbose=0)
    cnn_features.append(feat.flatten())

X_cnn = np.array(cnn_features)
print("âœ… Fitur CNN:", X_cnn.shape)

# === Scaling dan PCA ===
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_cnn)
pca = PCA(n_components=40, random_state=42)
X_pca = pca.fit_transform(X_scaled)

# === Train-Test Split ===
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, stratify=y, test_size=0.2, random_state=42)

# === Model Training ===
models = {
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
    "SVM (RBF)": SVC(kernel='rbf', probability=True, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Naive Bayes": GaussianNB(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
}

# === Confusion Matrix Visualization ===
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for idx, (name, model) in enumerate(models.items()):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(ax=axes[idx], cmap='Blues', colorbar=False)
    axes[idx].set_title(name)

# Kosongkan slot terakhir jika model < 6
if len(models) < len(axes):
    axes[-1].axis('off')

plt.suptitle("Confusion Matrices - CNN Features + 5 Classifiers", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

# === Evaluasi performa model berbasis fitur CNN ===
model_names = []
accuracies = []

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    model_names.append(name)
    accuracies.append(acc * 100)

# === Plot akurasi dalam diagram batang ===
plt.figure(figsize=(10,6))
sns.barplot(x=model_names, y=accuracies, palette='viridis')
plt.ylabel("Akurasi (%)")
plt.ylim(0, 100)
plt.title("Akurasi Model (Fitur CNN ResNet50)")
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 1, f"{acc:.2f}%", ha='center')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier

# === Siapkan model-model ===
models = {
    "Random Forest": RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),
    "SVM (RBF)": SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42),
    "Logistic Regression": LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),
    "Naive Bayes": GaussianNB(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
}

# === Simpan akurasi training dan testing ===
train_accuracies = []
test_accuracies = []
model_names = []

for name, model in models.items():
    model.fit(X_train, y_train)

    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)

    acc_train = accuracy_score(y_train, train_pred)
    acc_test = accuracy_score(y_test, test_pred)

    model_names.append(name)
    train_accuracies.append(acc_train * 100)
    test_accuracies.append(acc_test * 100)

    print(f"ðŸ“Œ {name} | Train Acc: {acc_train:.2f} | Test Acc: {acc_test:.2f}")

# === Plot akurasi dalam bentuk diagram batang ===
x = range(len(model_names))
width = 0.35

plt.figure(figsize=(12,6))
plt.bar(x, train_accuracies, width, label='Training Accuracy', color='skyblue')
plt.bar([p + width for p in x], test_accuracies, width, label='Testing Accuracy', color='orange')

# Tambahkan label di atas batang
for i in x:
    plt.text(i, train_accuracies[i] + 1, f"{train_accuracies[i]:.1f}%", ha='center')
    plt.text(i + width, test_accuracies[i] + 1, f"{test_accuracies[i]:.1f}%", ha='center')

# Label & legend
plt.xticks([p + width/2 for p in x], model_names, rotation=30)
plt.ylabel("Accuracy (%)")
plt.ylim(0, 110)
plt.title("Perbandingan Akurasi Training vs Testing (Fitur CNN ResNet50)")
plt.legend()
plt.tight_layout()
plt.grid(axis='y')
plt.show()

# === Import library ===
import joblib
import os

# === Buat folder model jika belum ada ===
os.makedirs("model", exist_ok=True)

# === Simpan model Random Forest, PCA, dan Scaler ke dalam satu file .pkl ===
model_bundle = {
    'model': rf,         # Random Forest model yang sudah dilatih
    'pca': pca,          # PCA untuk reduksi dimensi
    'scaler': scaler     # StandardScaler untuk normalisasi
}

# === Simpan ke file .pkl ===
joblib.dump(model_bundle, "model/parkinson_classifier.pkl")

print("âœ… Berhasil menyimpan model ke 'model/parkinson_classifier.pkl'")

!ls model/

import joblib

# Load model yang telah disimpan
loaded_data = joblib.load('model/parkinson_classifier.pkl')
model = loaded_data['model']
scaler = loaded_data['scaler']
pca = loaded_data['pca']

# Upload gambar spiral
uploaded = files.upload()

# Ambil nama file yang diupload
image_path = list(uploaded.keys())[0]

#uji prediksi gambar
# Load gambar dari user
img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
img = preprocess_image_grayscale(img)  # Resize & ubah ke RGB
img = np.expand_dims(img, axis=0)
img = tf.keras.applications.resnet50.preprocess_input(img)

# Ekstrak fitur CNN
feat = base_model.predict(img).flatten().reshape(1, -1)

# Preprocessing: scaler + PCA
feat_scaled = scaler.transform(feat)
feat_pca = pca.transform(feat_scaled)

# Prediksi kelas
prediksi_kelas = model.predict(feat_pca)[0]
print(f"Hasil prediksi: {prediksi_kelas}")

from google.colab import files
files.download('model/parkinson_classifier.pkl')