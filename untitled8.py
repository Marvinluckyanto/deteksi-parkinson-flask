# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14YkrTA7hQ8_iJRVpcMegEjUSpdzelUmO
"""

# === Umum ===
import os, cv2, zipfile, shutil
import numpy as np
import matplotlib.pyplot as plt

# === Model Klasik ===
from skimage.feature import hog
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.applications import ResNet50
import tensorflow as tf

# === Upload file ZIP di Colab ===
from google.colab import files
uploaded = files.upload()

# === Ekstrak ZIP ===
zip_path = "2Spiral_Parkinson.zip"
extract_path = "Spiral_Parkinson_4Class"

if os.path.exists(extract_path):
    shutil.rmtree(extract_path)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Dataset berhasil diekstrak.")

# === Fungsi Preprocessing ===
def preprocess_image_grayscale(img):
    img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    img_rgb = cv2.resize(img_rgb, (128,128))
    return img_rgb

def load_dataset(folder_path, num_classes=4):
    images = []
    labels = []
    for label in range(num_classes):
        folder = os.path.join(folder_path, str(label))
        for fname in os.listdir(folder):
            if fname.lower().endswith(('.png', '.jpg', '.jpeg')):
                fpath = os.path.join(folder, fname)
                img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)
                if img is not None:
                    img = preprocess_image_grayscale(img)
                    images.append(img)
                    labels.append(label)
    return np.array(images), np.array(labels)

X_img, y = load_dataset(extract_path)
print(f"âœ… Total gambar: {len(X_img)}")

# === Ekstrak fitur CNN ===
base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(128,128,3))
cnn_features = []
for img in X_img:
    x = np.expand_dims(img, axis=0)
    x = tf.keras.applications.resnet50.preprocess_input(x)
    feat = base_model.predict(x, verbose=0)
    cnn_features.append(feat.flatten())

X_cnn = np.array(cnn_features)
print("âœ… Shape fitur CNN:", X_cnn.shape)

# === Standarisasi & PCA ===
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_cnn)

pca = PCA(n_components=40, random_state=42)
X_pca = pca.fit_transform(X_scaled)

# === Split Train-Test ===
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, stratify=y, test_size=0.2, random_state=42)

# === Train Random Forest ===
rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("\nðŸ“Š Classification report (Random Forest + CNN features):")
print(classification_report(y_test, y_pred_rf))
ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test)
plt.title("Confusion Matrix - Random Forest")
plt.show()

# === Cross-Validation SVM ===
svm = SVC(kernel='rbf', class_weight='balanced', random_state=42)
scores = cross_val_score(svm, X_train, y_train, cv=5)
print(f"ðŸ“ˆ SVM (RBF) 5-fold CV Accuracy: {scores.mean()*100:.2f}%")

# === Train & Test SVM ===
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)

print("\nðŸ“Š Classification report (SVM - Testing Set):")
print(classification_report(y_test, y_pred_svm))
ConfusionMatrixDisplay.from_estimator(svm, X_test, y_test)
plt.title("Confusion Matrix - SVM")
plt.show()

acc_svm_test = accuracy_score(y_test, y_pred_svm)
print(f"âœ… SVM Testing Accuracy: {acc_svm_test * 100:.2f}%")

# === Import library untuk simpan model ===
import joblib
import os

# Buat folder jika belum ada
os.makedirs("model", exist_ok=True)

# Simpan pipeline model (scaler + PCA + Random Forest)
joblib.dump({
    'scaler': scaler,
    'pca': pca,
    'model': rf
}, 'model/parkinson_classifier.pkl')

print("âœ… Model, PCA, dan Scaler berhasil disimpan ke 'model/parkinson_classifier.pkl'")